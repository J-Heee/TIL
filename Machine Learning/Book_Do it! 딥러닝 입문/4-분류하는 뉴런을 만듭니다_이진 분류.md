# Chapter 4. 분류하는 뉴런을 만듭니다 - 이진 분류

## 2021.02.15

### 4-1. 초기 인공지능 알고리즘과 로지스틱 회귀
- **이진 분류(binary classification)** : 임의의 샘플 데이터를 True나 False로 구분하는 문제

<br>

#### 여러 개의 특성 사용
- 특성이 2개인 경우의 선형 함수
  - ![수식](https://latex.codecogs.com/svg.latex?z%20%3D%20w_1x_1%20&plus;%20w_2x_2%20&plus;%20b)
- 특성이 n개인 선형 함수
  - ![수식](https://latex.codecogs.com/svg.latex?z%20%3D%20w_1x_1%20&plus;%20w_2x_2%20&plus;%20%5Ccdots%20&plus;%20w_nx_n%20&plus;%20b)
  - ![수식](https://latex.codecogs.com/svg.latex?z%20%3D%20b%20&plus;%20%5Csum_%7Bi%3D1%7D%5En%20w_ix_i)
  - (n번째 특성의 가중치와 입력 의미)

<br>

#### 퍼셉트론(Perceptron)
- 1957년 발표한, 이진 분류 문제에서 최적의 가중치를 학습하는 알고리즘
- **퍼셉트론은 선형 함수에 계단 함수를 추가한 것**
- **계단 함수(step function)** : **샘플을 이진 분류**하기 위해 사용
  - 선형 함수를 통과한 값 z가
  - 0보다 크거나 같으면 : 1 (양성 클래스, positive class)
  - 0보다 작으면 : -1 (음성 클래스, negative class)
- 선형 함수의 결과값에 계단 함수를 적용하여 2개의 클래스 중 하나로 분류하는 알고리즘
- **계단 함수를 통과한 결과값을 사용하여 모델의 가중치와 절편 업데이트**
- 사이킷런 패키지에서 Perceptron이라는 이름으로 클래스 제공

<br>

#### 아달린(Adaline)
- 1960년 발표한, 퍼셉트론을 개선한 **적응형 선형 뉴런(Adaptive Linear Neuron)**
- **아달린은 선형 함수의 결과값을 학습에 사용**
- 계단 함수의 결과는 예측에만 활용
- 즉 역방향 계산이 계단 함수 출력 이후가 아닌, 선형 함수 출력 이후에 진행

<br>

#### 로지스틱 회귀(logistic regression)
- 아달린에서 조금 더 발전한 형태
- **선형 함수**를 통과시켜 얻은 값(z)으로 **-> 활성화 함수**를 통과시켜서 값(a)을 얻고 **-> 임계 함수**로 보내서 예측 수행(![수식](https://latex.codecogs.com/svg.latex?%5Cwidehat%7By%7D))
- **활성화 함수(activation function)** 
  - z를 임계 함수에 보내기 전에 변형시킴
  - 활성화 함수는 의무적으로 **비선형 함수를 사용**
    - 신경망의 각 층에서 수행되는 계산이 또 다른 큰 선형 함수가 되는 문제를 해결하기 위해서
  - 로지스틱 회귀에는 **시그모이드 함수** 사용
    - 선형 함수의 결과를 확률로 바꾸기 위해 사용
- **임계 함수(threshold function)** 
  - 아달린이나 퍼셉트론의 **계단 함수와 비슷한 역할**, 활성화 함수의 출력값을 사용한다는 차이점