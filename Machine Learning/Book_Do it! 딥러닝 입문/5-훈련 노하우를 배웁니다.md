# Chapter 5. 훈련 노하우를 배웁니다

## 2021.02.18

### 5-1. 검증 세트를 나누고 전처리 과정을 배운다
- 데이터 세트 중 '테스트 세트'의 사용 방법을 조금 더 깊이 공부
- 목표 : 어느 데이터 세트에만 치우친 모델을 만들지 않는 것

<br>

#### 테스트 세트로 모델 튜닝
- **로지스틱 회귀로 모델 훈련하고 평가하기**
  - 04장처럼 `cancer 데이터 세트`를 읽어 들여, 훈련 세트와 테스트 세트로 나눔 
  ```
  import numpy as np
  import matplotlib.pyplot as plt
  
  from sklearn.datasets import load_breast_cancer
  from sklearn.model_selection import train_test_split
  
  cancer = load_breast_cancer()
  x = cancer.data
  y = cancer.target
  x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)
  ```
  - `SGDClassifier` 클래스를 이용하여 로지스틱 회귀 모델 훈련
  ```
  from sklearn.linear_model import SGDClassifier
  sgd = SGDClassifier(loss='log', random_state=42)
  sgd.fit(x_train_all, y_train_all)        # 훈련
  sgd.score(x_test, y_test)                # 성능 평가

  # 출력
  # 0.8333333333333334
  ```
  - 테스트 세트에서 정확도는 약 83%
  - 이 성능이 만족스럽지 않다면 다른 손실 함수 사용 가능
  - 그러나, **`loss`와 같은 매개변수의 값은 사용자가 직접 선택해야 함**
    - 가중치나 절편처럼 알아서 학습되지 않음
    - 이런 값을 **하이퍼파라미터(hyperparameter)** 라고 부름
- **서포트 벡터 머신으로 모델 훈련하고 평가하기**
  - 선형 서포트 벡터 머신(Support Vector Machine; SVM) 문제를 푸는 모델 생성
    - `SGDClassifier` 클래스의 `loss` 매개변수를 `log`에서 `hinge`로 바꾸기
    - SVM은 훈련 데이터의 클래스를 구분하는 경계선을 찾는 작업
  ```
  from sklearn.linear_model import SGDClassifier
  sgd = SGDClassifier(loss='hinge', random_state=42)
  sgd.fit(x_train_all, y_train_all)        # 훈련
  sgd.score(x_test, y_test)                # 성능 평가

  # 출력
  # 0.9385964912280702
  ```
  - 테스트 세트에서 정확도는 약 93%
  - 로지스틱 회귀로 만든 모델의 성능보다 더 좋음
  - **'모델을 튜닝한다'** : 성능이 만족스럽지 않을 경우, 이처럼 SGDClassifier 클래스의 **다른 매개변수들을 바꿔보는 작업**
  - 모델을 튜닝하여 테스트 세트에 대해 좋은 성능을 내는 모델을 만들어보았지만, 이 모델은 실전에서 좋은 성능을 내지 못할 확률이 높음

<br>

#### 테스트 세트로 모델을 튜닝하면 실전에서 좋은 성능을 기대하기 어렵다
- 테스트 세트는 실전에 투입된 모델의 성능을 측정하기 위해 사용
- 그러한 테스트 세트로 모델을 튜닝하면 **'테스트 세트에 대해서만 좋은 성능을 보여주는 모델'** 이 생성됨
  - => **'테스트 세트의 정보가 모델에 새어 나갔다'**
- 결과적으로 **모델의 일반화 성능이 왜곡**됨

<br>

#### 검증 세트 준비
- 테스트 세트는 모델 튜닝을 모두 마치고 실전에 투입하기 전에 딱 한 번만 사용하는 것이 좋음
- **검증 세트(validation set) : 모델을 튜닝하는 용도의 세트**
  - 검증 세트를 따로 준비해야 함
  - 훈련 세트를 조금 떼어 만듦
  - 개발 세트(dev set)라고도 부름
- **훈련 세트, 검증 세트, 테스트 세트는 일반적으로 6:2:2의 비율로 나눔**
- 전체 데이터 세트를 위의 3개로 나누고 SGDClassfier 클래스로 만든 모델 훈련하기
  1. 데이터 세트 준비하기
     - 동일하게 위스콘신 유방암 데이터 사용
  2. 검증 세트 분할하기
     ```
     x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)
     print(len(x_train), len(x_val))

     # 출력
     # 364 91
     ```
     - 실제 분할 작업은 처음부터 6:2:2 비율로 나누는 것 아님
     - **전체 데이터 세트를 8:2로 나누어 훈련 세트와 테스트 세트를 만들고 -> 다시 훈련 세트를 8:2로 나누어 훈련 세트와 검증 세트를 만듦**
     - 과정 1번에서 이미 전체 데이터 세트를 8:2로 나누었으므로, 여기서 훈련 세트를 다시 8:2로 나눔
     - 455개의 훈련 세트가 8:2로 나누어져 훈련 세트 364개, 검증 세트 91개
  3. 검증 세트 사용해 모델 평가하기
     ```
     sgd = SGDClassifier(loss='log', random_state=42)
     sgd.fit(x_train, y_train)
     sgd.score(x_val, y_val)

     # 출력
     # 0.6923076923076923
     ```
     - 검증 세트로 모델을 평가하니 이전보다 평가 점수가 낮아짐
       - **훈련 세트의 크기가 줄어들었기 때문**
- 위스콘신 유방암 데이터 세트의 샘플 개수는 적은편이라, 검증 세트의 비율을 조금만 조절해도 성능 평가 점수가 크게 변함
- 데이터 양이 너무 적은 경우, 검증 세트를 나누지 않고 **교차 검증(cross validation)** 방법을 사용하기도 함
- 하지만 요즘은 대량의 훈련 데이터를 손쉽게 모을 수 있음

<br>

#### 데이터 전처리와 특성의 스케일
- **데이터 전처리(data preprocessing)**
  - 머신러닝 패키지에 준비되어 있는 데이터는 대부분 실습을 위한 것이므로 잘 가공되어 있음
  - 실전에서 수집된 데이터는 누락되거나 형태가 균일하지 않을 수 있음
  - 이런 경우 **데이터를 적절히 가공**하는 데이터 전처리 과정 필요
- **특성의 스케일(scale)은 알고리즘에 영향을 줌**
  - 잘 정리된 데이터도 특성의 스케일이 다른 경우 전처리가 필요함
  - **특성의 스케일 : 어떤 특성이 가지고 있는 값의 범위**
  - '두 특성의 스케일 차이가 크다'
    - ex) 사과의 당도 범위는 1~10인데, 사과의 무게 범위는 500~1000인 경우 
  - **'스케일을 조정한다' : 특성의 스케일을 전처리하는 것**
    - **경사 하강법은 스케일에 민감한 알고리즘**이라 모델의 성능에 영향을 줌
    - 특성의 스케일을 맞추는 등의 전처리 필요

<br>

#### 스케일을 조정하지 않고 모델 훈련해보기
- 특성의 스케일이 서로 다른 데이터로 모델을 훈련하여 가중치 변화 살펴보기
- 실습에서 위스콘신 유방암 데이터와 04장에서 만든 단일층 신경망 모델 사용
1. 훈련 데이터 준비하고 스케일 비교하기
   ```
   print(cancer.feature_names[[2,3]])
   plt.boxplot(x_train[:, 2:4])         # 박스 플롯 그림
   plt.xlabel('feature')
   plt.ylabel('value')
   plt.show()

   # 출력
   # ['mean perimeter' 'mean area']
   ```
   - 특성의 스케일을 비교해야 하므로 유방암 데이터의 `mean perimeter`와 `mean area` 특성을 가져옴
   - **박스 플롯 그래프를 통해 두 특성의 스케일 차이 확인 가능**
     - `mean perimete` : 주로 100~200 사이에 값들이 위치
     - `mean area` : 주로 200~2,000 사이에 값들이 위치   
2. 가중치를 기록할 변수와 학습률 파라미터 추가하기
   ```
   def __init__(self, learning_rate=0.1):
       self.w = None
       self.b = None
       self.losses = []
       self.w_history = []
       self.lr = learning_rate
   ```
   - `w_history` : 인스턴스 변수를 추가하여 에포크마다 가중치의 값을 저장하여, 가중치 변화 관찰에 사용
   - `learning_rate` : **하이퍼파라미터**로, **'학습률'** 의미, 이 값으로 **가중치의 업데이트 양 조절**할 것
   - 일반적으로 손실 함수는 복잡한 굴곡을 가진 다차원 공간의 초평면(hyperplane)
   - **전역 최솟값 : 손실 함수가 최소가 될 수 있는 지점**
     - 학습률이 너무 높으면 가중치를 큰 폭으로 업데이트하게 되어 전역 최솟값을 지나쳐 버리게 되면 최적의 해(최적의 가중치와 절편)를 구할 수 없음
     - 학습률이 적절해야 가중치의 변화가 안정적이므로 천천히 전역 최솟값에 잘 도달함
     - 보통 0.001, 0.01 등의 로그 스케일로 학습률 지정하여 테스트
3. 가중치 기록하고 업데이트 양 조절하기
   ```
   def fit(self, x, y, epochs=100, x_val=None, y_val=None):
        self.w = np.ones(x.shape[1])               # 가중치 초기화
        self.b = 0                                 # 절편 초기화
        self.w_history.append(self.w.copy())       # 가중치 기록
        np.random.seed(42)                         # 랜덤 시드 지정
        for i in range(epochs):                    # epochs만큼 반복
            loss = 0
            # 인덱스를 섞음
            indexes = np.random.permutation(np.arange(len(x)))
            for i in indexes:                      # 모든 샘플에 대해 반복
                z = self.forpass(x[i])             # 정방향 계산
                a = self.activation(z)             # 활성화 함수 적용
                err = -(y[i] - a)                  # 오차 계산
                w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산
                self.w -= self.lr * w_grad         # 가중치 업데이트(학습률 적용)
                self.b -= b_grad                   # 절편 업데이트
                # 가중치 기록
                self.w_history.append(self.w.copy())
                # 안전한 로그 계산을 위해 클리핑한 후 손실을 누적
                a = np.clip(a, 1e-10, 1-1e-10)
                loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a))
            # 에포크마다 평균 손실 저장
            self.losses.append(loss/len(y) + self.reg_loss())
   ```
   - `fit()` 메서드에서 가중치가 바뀔 때마다 `w_history`리스트에 가중치 기록
   - `w_grad`에 학습률 `self.lr`을 곱하는 연산이 추가되어 가중치 업데이트 양을 조절
4. 모델 훈련하고 평가하기
   ```
   layer1 = SingleLayer()
   layer1.fit(x_train, y_train)
   layer1.score(x_val, y_val)

   # 출력
   # 0.9120879120879121
   ```
   - 스케일을 조정하지 않은 훈련 세트로 훈련한 모델의 성능 점수는 약 91%의 정확도를 보임
5. 그래프로 확인하기
   ```
   w2 = []
   w3 = []
   for w in layer1.w_history:
       w2.append(w[2])
       w3.append(w[3])
   plt.plot(w2, w3)
   plt.plot(w2[-1], w3[-1], 'ro')
   plt.xlabel('w[2]')
   plt.ylabel('w[3]')
   plt.show()
   ```
   - `layer1` 객체의 인스턴스 변수 `w_history`에는 100번의 에포크 동안 변경된 가중치가 모두 기록되어 있음
     - 세 번째(w[2]), 네 번째(w[3]) 요소는 각각 `mean perimeter`와 `mean area` 특성에 대한 가중치 => 그래프 그림
     - 최종으로 결정된 가중치 => 점으로 표시
   - 그래프의 현상은 **'w3에 대한 그레이디언트가 크기 때문에, w3 축을 따라 가중치가 크게 요동치고 있다'**
     - w3 값은 학습 과정에서 큰 폭으로 흔들리며 변화
     - w2 값은 0부터 시작하여 조금씩 최적값에 가까워짐
     - 이런 현상은 스케일 조정을 통해 줄일 수 있음

<br>

#### 스케일을 조정해 모델 훈련
- **표준화(standardization)** : 신경망에서 자주 사용하는 **스케일 조정 방법** 중 하나
  - **특성값에서 평균을 빼고 표준 편차로 나누는 것**
  - 표준화를 하면 평균이 0이고 분산이 1인 특성이 만들어짐
1. 넘파이로 표준화 구현하기
   ```
   train_mean = np.mean(x_train, axis=0)            # 평균 계산
   train_std = np.std(x_train, axis=0)              # 표준 편차 계산
   x_train_scaled = (x_train - train_mean) / train_std      # 훈련 세트에서 평균을 빼고 표준 편차로 나누기
   ```
   - 넘파이의 `mean()`, `std()` 함수의 `axis` 매개변수를 0으로 지정 : 2차원 배열의 열을 기준으로 통계치를 계산하여 하나의 행 벡터로 반환
2. 모델 훈련하기
   - 스케일을 조정한 데이터 세트로 단일층 신경망을 다시 훈련시키고, 가중치 그래프 그리기
   ```
   layer2 = SingleLayer()
   layer2.fit(x_train_scaled, y_train)
   w2 = []
   w3 = []
   for w in layer2.w_history:
       w2.append(w[2])
       w3.append(w[3])
    plt.plot(w2, w3)
    plt.plot(w2[-1], w3[-1], 'ro')
    plt.xlabel('w[2]')
    plt.ylabel('w[3]')
    plt.show()
   ```
   - w2와 w3의 변화 비율이 비슷하므로 **대각선 방향으로 가중치가 이동함**
   - 두 특성의 스케일을 비슷하게 맞추었으므로, 최적값에 빠르게 근접하고 있음
   - **=> 경사 하강법에서는 서로 다른 특성의 스케일을 맞추는 것이 아주 중요함!**
3. 검증 세트에서 모델 성능 평가하기
   ```
   layer2.score(x_val, y_val)

   # 출력
   # 0.37362637362637363
   ```
   - 성능이 매우 안좋음
   - **검증 세트의 스케일을 바꾸지 않았기 때문**
4. 검증 세트에 표준화 전처리 적용
   ```
   val_mean = np.mean(x_val, axis=0)
   val_std = np.std(x_val, axis=0)
   x_val_scaled = (x_val - val_mean) / val_std
   layer2.score(x_val_scaled, y_val)

   # 출력
   # 0.967032967032967
   ```
   - 검증 세트에 대한 정확도가 약 96%
   - 그러나 아직 조심해야 할 함정이 있음

<br>

#### 스케일 조정 후 실수하기 쉬운 함정
- **'훈련 세트와 검증 세트가 다른 비율로 스케일이 조정된 경우'**
- 원본 훈련 세트와 검증 세트, 전처리된 훈련 세트와 검증 세트에서 데이터를 50개씩 뽑아 산점도를 그려 비교
1. 원본 훈련 세트와 검증 세트로 산점도 그리기
   - 파란 점: 훈련 세트, 빨간 점: 검증 세트
   ```
   plt.plot(x_train[:50, 0], x_train[:50, 1], 'bo')
   plt.plot(x_val[:50, 0], x_val[:50, 1], 'ro')
   plt.xlabel('feature 1')
   plt.ylabel('feature 2')
   plt.legend(['train set', 'val. set'])
   plt.show()
   ```
2. 전처리한 훈련 세트와 검증 세트로 산점도 그리기
   ```
   plt.plot(x_train_scaled[:50, 0], x_train_scaled[:50, 1], 'bo')
   plt.plot(x_val_scaled[:50, 0], x_val_scaled[:50, 1], 'ro')
   plt.xlabel('feature 1')
   plt.ylabel('feature 2')
   plt.legend(['train set', 'val. set'])
   plt.show()
   ```
   - 과정 1의 산점도와 자세히 비교해서 보면, 미세하지만 훈련 세트와 검증 세트가 각각 다른 비율로 변환되었음
   - 원본 훈련 세트와 검증 세트의 점과 점 사이의 거리가 변환된 이후에 그대로 유지되지 않음
     - 제대로 전처리했다면 점 사이의 거리가 그대로 유지되어야 함
   - **=> 훈련 세트와 검증 세트를 각각 다른 비율로 전처리했기 때문**
3. 올바르게 검증 세트 전처리하기
   - 검증 세트를 훈련 세트와 같은 비율로 전처리해야 함
   - **훈련 세트의 평균, 표준 편차를 사용하여 검증 세트를 변환!**
   ```
   x_val_scaled = (x_val - train_mean) / train_std
   
   plt.plot(x_train_scaled[:50, 0], x_train_scaled[:50, 1], 'bo')
   plt.plot(x_val_scaled[:50, 0], x_val_scaled[:50, 1], 'ro')
   plt.xlabel('feature 1')
   plt.ylabel('feature 2')
   plt.legend(['train set', 'val. set'])
   plt.show()
   ```
   - 원본 데이터의 산점도와 스케일 조정 이후의 산점도가 동일해짐
4. 검증 세트로 모델의 성능 평가하기
   ```
   layer2.score(x_val_scaled, y_val)

   # 출력
   # 0.967032967032967
   ```
   - 여기서 사용한 위스콘신 유방암 데이터 세트는 크지 않기 때문에, 검증 세트 전처리 전후의 성능이 동일
   - 그러나 검증 세트가 클 경우 성능에 차이가 나타날 수 있음
- **데이터를 전처리할 때 훈련 세트의 통계값으로 검증 세트와 테스트 세트를 변환해야 함!**

<br>
<br>

### 5-2. 과대적합과 과소적합
- 훈련 세트와 검증 세트는 모델의 과대적합, 과소적합이라는 문제와 깊은 연관이 있음

<br>

#### 학습 곡선(learning curve)을 통해 과대적합과 과소적합 알아보기
- (책 p.131 그래프 참고)
- **훈련 세트의 크기와 과대적합, 과소적합 분석**
- **과대적합(overfitting) : 모델이 훈련 세트에서는 좋은 성능을 내지만, 검증 세트에서는 낮은 성능을 내는 경우**
  - 훈련 세트와 검증 세트에서 측정한 성능의 간격이 큼 **(분산이 크다)**
  - 주요 원인 : 훈련 세트에 충분히 다양한 패턴의 샘플이 없는 경우
    - 더 많은 훈련 샘플을 모아 검증 세트의 성능 향상 가능
  - 현실적인 한계로 훈련 샘플을 더 모을 수 없는 경우
    - 모델이 훈련 세트에 집착하지 않도록 가중치를 제한 (모델의 복잡도를 낮춘다)  
- **과소적합(underfitting) : 훈련 세트와 검증 세트의 성능에는 차이가 크지 않지만, 모두 낮은 성능을 내는 경우**
  - 훈련 세트와 검증 세트에서 측정한 성능의 간격은 점점 가까워지지만 성능 자체가 낮음 **(편향이 크다)**
  - 모델이 충분히 복잡하지 않아 훈련 데이터에 있는 패턴을 모두 잡아내지 못하는 현상
    - 복잡도가 더 높은 모델을 사용해서 해결
    - 가중치의 규제를 완화해서 해결
- **에포크와 손실 함수의 그래프로도 과대적합과 과소적합 분석 가능**
  - (책 p.132 그래프 참고)
  - 훈련 세트의 손실은 에포크가 진행될수록 감소
  - 검증 세트의 손실은 에포크의 횟수가 최적점을 지나면 오히려 상승 => 모델이 과대적합되기 시작
    - 최적점 이후에도 계속해서 훈련 세트로 학습시키면, 모델이 훈련 세트의 샘플에 더 밀착하여 학습하기 때문
  - 최적점 이전에서 학습을 중지하면 과소적합된 모델
    - 훈련 세트와 검증 세트의 손실이 비슷한 간격을 유지하면서 함께 감소   
- **모델 복잡도와 손실 함수의 그래프로도 과대적합과 과소적합 분석 가능**
  - 모델 복잡도 : 모델이 가진 학습 가능한 가중치 개수
    - 층의 개수나 유닛의 개수가 많아지면 복잡도 높은 모델
  - (책 p.133 참고)

<br>

#### 적절한 편향-분산 트레이드오프 선택
- **편향-분산 트레이드오프(bias-variance tradeoff) : 과소적합된 모델(편향)과 과대적합된 모델(분산) 사이의 관계**
- 트레이드오프인 이유 : 하나를 얻기 위해서는 다른 하나를 희생해야 하기 때문
  - **편향을 줄이면(훈련 세트의 성능을 높이면), 분산이 커짐(검증 세트와 성능 차이가 커짐)**
  - 분산을 줄이면, 편향이 커짐
- 적절한 편향-분산 트레이드오프를 선택해야 함

<br>

- 경사 하강법의 **에포크 횟수에 대한 모델의 손실**을 그래프로 그려 '적절한 편향-분산 트레이드오프' 선택
1. 검증 손실을 기록하기 위한 변수 추가하기
   - `SingleLayer` 클래스의 `__init__()` 메서드에 `self.val_losses` 인스턴스 변수 추가
2. `fit()` 메서드에 검증 세트를 전달받을 수 있도록 `x_val`, `y_val` 매개변수 추가하기
3. 검증 손실 계산하기
   ```
   def update_val_loss(self, x_val, y_val):
       if x_val is None:
           return
       val_loss = 0
       for i in range(len(x_val)):
           z = self.forpass(x_val[i])     # 정방향 계산
           a = self.activation(z)         # 활성화 함수 적용
           a = np.clip(a, 1e-10, 1-1e-10)
           val_loss += -(y_val[i]*np.log(a)+(1-y_val[i])*np.log(1-a))
       self.val_losses.append(val_loss/len(y_val) + self.reg_loss())
   ```
   - `fit()` 에서 훈련 세트의 손실을 계산하는 방식과 동일
4. 모델 훈련하기
   - 모델의 수정을 완료했으므로, 표준화된 훈련 세트와 검증 세트를 이용하여 단일층 신경망 훈련
   ```
   layer3 = SingleLayer()
   layer3.fit(x_train_scaled, y_train, x_val=x_val_scaled, y_val=y_val)
   ```
5. 손실값으로 그래프 그려 에포크 횟수 지정하기
   ```
   plt.ylim(0, 0.3)
   plt.plot(layer3.losses)
   plt.plot(layer3.val_losses)
   plt.ylabel('loss')
   plt.xlabel('epoch')
   plt.legend(['train_loss', 'val_loss'])
   plt.show()
   ```
   - 에포크마다 훈련 세트와 검증 세트의 손실값이 `self.val_losses`에 저장되어 있음
   - 그래프를 보면 대략 20번째 에포크 이후에 검증 손실이 훈련 세트보다 높아짐
     - 이 모델은 20번의 에포크 이후에는 훈련할 필요가 없음 
6. 훈련 조기 종료하기
   - **조기 종료(early stopping)** : 훈련을 일찍 멈추는 기법
   - 20번의 에포크까지 모델을 훈련하고 검증 세트의 성능 확인
     ```
     layer4 = SingleLayer()
     layer4.fit(x_train_scaled, y_train, epochs=20)
     layer4.score(x_val_scaled, y_val)

     # 출력
     # 0.978021978021978
     ```
     - 과대적합되기 전에 훈련을 멈추었으므로, 검증 세트의 성능이 0.967에서 0.978로 조금 더 향상됨

<br>
<br>

### 5-3. 규제 방법을 배우고 단일층 신경망에 적용
- **가중치 규제(regularization) : 가중치의 값이 커지지 않도록 제한하는 기법**
  - 과대적합을 해결하는 대표적인 방법 중 하나
  - 가중치를 규제하면 **모델의 일반화 성능이 올라감**
- 모델이 몇 개의 데이터에 집착하면 새로운 데이터에 적응하지 못하므로, 좋은 성능을 가졌다고 할 수 없음
  - '모델이 일반화되지 않았다'
  - 규제를 사용하면 모델이 몇 개의 데이터에 집착하지 않게 됨

<br>

#### L1 규제
- **L1 규제 : 손실 함수에 가중치의 절댓값인 L1 노름(norm)을 추가한 것**
  - '가중치의 절댓값을 손실 함수에 더한 것' 
  - 소문자 알파벳 : 벡터 의미, 볼드로 된 대문자 알파벳 : 행렬 의미
  - (책 p.138 수식 참고)
- 로지스틱 손실 함수에 L1 규제를 적용
  - 손실 함수에 L1 노름을 그냥 더하지 않고, 규제의 양을 조절하는 파라미터(α)를 곱한 후 더함
- **α : L1 규제의 양을 조절하는 하이퍼파라미터**
  - **규제가 강해졌다(가중치가 작아졌으므로) : α값이 크면** 전체 손실 함수의 값이 커지지 않도록 w의 값의 합이 작아져야 함
  - 규제가 약해졌다 : α값이 작으면 w의 합이 커져도 손실 함수의 값이 큰 폭으로 커지지 않음

<br>

#### L1 규제의 미분
- 경사 하강법으로 가중치를 업데이트하기 위해 미분
- `sign(w)` : 절댓값을 미분하면 부호만 남기 때문에 **w의 부호라는 의미**로 표현
- **L1 규제를 추가한 로지스틱 손실 함수를 경사 하강법으로 최적화하는 방법**
  - 규제 하이퍼파라미터 α와 가중치의 부호를 곱해서, 업데이트할 그레이디언트에 더해주는 것
  ```
  w_grad += alpha * np.sing(w)
  ``` 
  - `alpha` 변수 : 규체 하이퍼파라미터
  - `np.sign()` 함수 : 배열 요소의 부호를 반환
- **절편에 대한 규제는 하지 않음**
  - 절편을 규제하면 모델을 어떤 방향으로 이동시킬 뿐 복잡도에는 영향을 주지 않음
- `SGDClassifier` 클래스에서 `penalty` 매개변수 값을 `l1`으로 지정하는 방법으로 L1 규제 적용 가능
  - 규제의 강도를 제어하는 하이퍼파라미터를 위한 `alpha` 매개변수도 제공
- **라쏘(Lasso) 모델 : 회귀 모델에 L1 규제를 추가한 것**
  - 라쏘는 **일부 가중치를 0으로** 만들 수 있음
  - 가중치가 0인 특성은 모델에서 사용할 수 없다는 것과 같은 의미
  - -> 특성을 선택하는 효과
  - -> 그러나 모델의 복잡도가 떨어짐
  - 사이킷런의 `sklearn.linear_model.Lasso` 클래스에서 라쏘 모델 제공

<br>

#### L2 규제
- **L2 규제 : 손실 함수에 가중치에 대한 L2 노름(norm)의 제곱을 더한 것**
  - α : L1 규제와 마찬가지로 규제의 양을 조절하기 위한 하이퍼파라미터
  - (책 p.140 수식 참고)

<br>

#### L2 규제의 미분
- L2 규제를 미분하면, 간단히 **가중치 벡터 w만 남음**
- **L2 규제를 경사 하강법 알고리즘에 적용하는 방법**
  - 그레이디언트에 α와 가중치의 곱을 더하는 것
  ```
  w_grad += alpha * w
  ``` 
  - 그레이디언트 계산에 가중치의 값 자체가 포함되므로, 가중치의 부호만 사용하는 L1 규제보다 효과적
  - L2 규제는 가중치를 완전히 0으로 만들지도 않음
  - => **실무에서는 규제 효과가 뛰어난 L2 규제를 주로 사용함**
- **릿지(Ridge) 모델 : 회귀 모델에 L2 규제를 적용한 것**
  - 사이킷런의 `sklearn.linear_model.Ridge` 클래스에서 릿지 모델 제공
  - `SGDClassifier` 클래스에서 `penalty` 매개변수 값을 `l2`으로 지정하는 방법으로 L2 규제 적용 가능
  - 두 클래스 모두 규제의 강도는 `alpha` 매개변수로 제어

<br>

#### 로지스틱 회귀에 규제 적용
- 04장에서 만든 `SingleLayer` 클래스에 L1 규제와 L2 규제를 적용하기 위한 코드 추가하고 훈련
- 차이점을 알아보기 위해 두 규제 모두 구현
1. 그레이디언트 업데이트 수식에 페널티 항 반영하기
   - `__init__()` 메서드에 각 규제의 강도를 조절하는 매개변수 `l1`과 `l2` 추가
   - `l1`과 `l2`의 기본값은 0이고, 이때는 규제를 적용하지 않음
2. `fit()` 메서드에서 역방향 계산을 수행할 때, 그레이디언트에 페널티 항의 미분값을 더함
   - 이때 L1 규제와 L2 규제를 하나의 식으로 동시에 수행
3. 로지스틱 손실 함수 계산에 페널티 항 추가하기
   ```
   def reg_loss(self):
       return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)
   ```
   - 이 함수는 훈련 세트와 검증 세트의 로지스틱 손실 함수의 값을 계산할 때 모두 호출됨
4. 검증 세트의 손실을 계산하는 `update_val_loss()` 메서드에서 `reg_loss()`를 호출하도록 수정
- 여기까지의 코드
  ```
  class SingleLayer:
    
    def __init__(self, learning_rate=0.1, l1=0, l2=0):
        self.w = None
        self.b = None
        self.losses = []
        self.val_losses = []
        self.w_history = []
        self.lr = learning_rate
        self.l1 = l1
        self.l2 = l2

    def forpass(self, x):
        z = np.sum(x * self.w) + self.b    # 직선 방정식 계산
        return z

    def backprop(self, x, err):
        w_grad = x * err          # 가중치에 대한 그래디언트 계산
        b_grad = 1 * err    # 절편에 대한 그래디언트 계산
        return w_grad, b_grad

    def activation(self, z):
        z = np.clip(z, -100, None) # 안전한 np.exp() 계산을 위해
        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산
        return a
        
    def fit(self, x, y, epochs=100, x_val=None, y_val=None):
        self.w = np.ones(x.shape[1])               # 가중치 초기화
        self.b = 0                                 # 절편 초기화
        self.w_history.append(self.w.copy())       # 가중치 기록
        np.random.seed(42)                         # 랜덤 시드 지정
        for i in range(epochs):                    # epochs만큼 반복
            loss = 0
            # 인덱스를 섞음
            indexes = np.random.permutation(np.arange(len(x)))
            for i in indexes:                      # 모든 샘플에 대해 반복
                z = self.forpass(x[i])             # 정방향 계산
                a = self.activation(z)             # 활성화 함수 적용
                err = -(y[i] - a)                  # 오차 계산
                w_grad, b_grad = self.backprop(x[i], err) # 역방향 계산
                # 그래디언트에서 페널티 항의 미분 값을 더함
                w_grad += self.l1 * np.sign(self.w) + self.l2 * self.w
                self.w -= self.lr * w_grad         # 가중치 업데이트
                self.b -= b_grad                   # 절편 업데이트
                # 가중치 기록
                self.w_history.append(self.w.copy())
                # 안전한 로그 계산을 위해 클리핑한 후 손실 누적
                a = np.clip(a, 1e-10, 1-1e-10)
                loss += -(y[i]*np.log(a)+(1-y[i])*np.log(1-a))
            # 에포크마다 평균 손실 저장
            self.losses.append(loss/len(y) + self.reg_loss())
            # 검증 세트에 대한 손실 계산
            self.update_val_loss(x_val, y_val)
    
    def predict(self, x):
        z = [self.forpass(x_i) for x_i in x]     # 정방향 계산
        return np.array(z) >= 0                   # 스텝 함수 적용
    
    def score(self, x, y):
        return np.mean(self.predict(x) == y)
    
    def reg_loss(self):
        return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)
    
    def update_val_loss(self, x_val, y_val):
        if x_val is None:
            return
        val_loss = 0
        for i in range(len(x_val)):
            z = self.forpass(x_val[i])     # 정방향 계산
            a = self.activation(z)         # 활성화 함수 적용
            a = np.clip(a, 1e-10, 1-1e-10)
            val_loss += -(y_val[i]*np.log(a)+(1-y_val[i])*np.log(1-a))
        self.val_losses.append(val_loss/len(y_val) + self.reg_loss())
  ```
5. **cancer 데이터 세트에 L1 규제 적용하기**
   - L1 규제 강도(0.0001, 0.001, 0.01)에 따라 모델의 학습 곡선과 가중치의 변화 확인
   - for문을 사용하여 각각 다른 강도의 하이퍼파라미터로 모델 생성하고 학습 곡선과 가중치 그래프로 나타내기
   ```
   l1_list = [0.0001, 0.001, 0.01]

   for l1 in l1_list:
       lyr = SingleLayer(l1=l1)
       lyr.fit(x_train_scaled, y_train, x_val=x_val_scaled, y_val=y_val)
    
       plt.plot(lyr.losses)
       plt.plot(lyr.val_losses)
       plt.title('Learning Curve (l1={})'.format(l1))
       plt.ylabel('loss')
       plt.xlabel('epoch')
       plt.legend(['train_loss', 'val_loss'])
       plt.ylim(0, 0.3)
       plt.show()
    
       plt.plot(lyr.w, 'bo')
       plt.title('Weight (l1={})'.format(l1))
       plt.ylabel('value')
       plt.xlabel('weight')
       plt.ylim(-4, 4)
       plt.show()
   ```
   - 그래프의 가시성을 위해 맷플롯립의 `title()`로 제목 넣고, `ylim()`로 y축의 범위 제한
   - 학습 곡선 그래프를 보면, 규제가 더 커질수록 훈련 세트의 손실과 검증 세트의 손실이 모두 높아짐 => 과소적합 현상
   - 가중치 그래프를 보면, 규제 강도 l1 값이 커질수록 가중치의 값이 0에 가까워짐
   - **-> 적절한 l1 하이퍼파라미터 값은 0.001 정도**
     - 이 값으로 모델의 성능 확인
     ```
     layer5 = SingleLayer(l1=0.001)
     layer5.fit(x_train_scaled, y_train, epochs=20)
     layer5.score(x_val_scaled, y_val)

     # 출력
     # 0.978021978021978
     ``` 
     - 규제를 적용하지 않고 검증 세트로 평가했을 때의 값과 동일
     - -> 규제 효과가 크게 나타나지 않음
6. **cancer 데이터 세트에 L2 규제 적용하기**
   ```
   l2_list = [0.0001, 0.001, 0.01]
   ```
   - 과정 5와 같은 방법으로 L2 규제의 강도 조절하고 모델 훈련
   - L1 규제와 비슷한 양상이지만, 마지막 학습 곡선 그래프를 보면 L2 규제는 규제 강도가 강해져도 **L1 규제만큼 과소적합이 심해지지는 않음**
   - 가중치 그래프도 **가중치가 0에 너무 가깝게 줄어들지 않음**
   - L2 규제를 적용한 모델을 50번의 에포크 횟수만큼 훈련하고 성능 평가
     ```
     layer6 = SingleLayer(l2=0.01)
     layer6.fit(x_train_scaled, y_train, epochs=50)
     layer6.score(x_val_scaled, y_val)
     # 출력
     # 0.978021978021978
     ```
     - cancer 데이터 세트의 샘플 개수가 아주 적어서 결과가 L1 규제와 동일함
     - 두 모델 모두 91개의 검증 샘플 중 89개의 샘플을 올바르게 예측함
     ```
     np.sum(layer6.predict(x_val_scaled) == y_val)

     # 출력
     # 89
     ```
     - 하지만, **L1 규제를 사용했을 때보다 에포크가 20번에서 50번으로 크게 증가함**
     - 가중치를 강하게 제한했기 때문에, 검증 세트의 손실값을 일정한 수준으로 유지하면서 알고리즘이 전역 최솟값을 찾는 과정을 오래 반복할 수 있었던 것
7. `SGDClassifier`에서 규제 사용하기
   - 사이킷런의 `SGDClassifier` 클래스도 L1 규제, L2 규제를 지원함
   - cancer 데이터 세트를 사용하여 L2 규제를 적용
     ```
     sgd = SGDClassifier(loss='log', penalty='l2', alpha=0.001, random_state=42)
     sgd.fit(x_train_scaled, y_train)
     sgd.score(x_val_scaled, y_val)

     # 출력
     # 0.978021978021978
     ```
     - `SingleLayer` 클래스와 동일한 결과
- 사이킷런에는 L1 규제와 L2 규제를 지원하는 다양한 모델 존재
  - ex) `LogisticRegression`, `SVC`, `LinearSVC` 클래스 등
  - 이 클래스들은 페널티 항 대신 주손실 함수의 크기를 조절하기 위해 하이퍼파라미터 C를 곱함
  - C와 alpha는 반대의 역할
  - 매개변수 C가 커지면, 규제가 줄어드는 방식

<br>
<br>

### 5-4. 교차 검증을 알아보고 사이킷런으로 수행
- 전체 데이터 세트의 샘플 개수가 많지 않을 때, 검증 세트를 훈련 세트에서 분리하느라 훈련 세트의 샘플 개수가 줄어들어 모델을 훈련시킬 데이터가 부족해지는 경우 -> 교차 검증 사용

<br>

#### 교차 검증의 원리
- **폴드(fold) : 훈련 세트를 나눈 작은 덩어리**
- 교차 검증은 훈련 세트를 폴드로 나누어 진행
- **교차 검증 과정**
  1. 훈련 세트를 k개의 폴드로 나눈다.
  2. 첫 번째 폴드를 검증 세트로 사용하고 나머지 폴드(k-1개)를 훈련 세트로 사용한다.
  3. 모델을 훈련한 다음에 검증 세트로 평가한다.
  4. 차례대로 다음 폴드를 검증 세트로 사용하여 반복한다.
  5. k개의 검증 세트로 k번 성능을 평가한 후 계산된 성능의 평균을 내어 최종 성능을 계산한다.
- **k-폴드 교차 검증**
  - 교차 검증은 훈련 세트를 k개의 폴드로 나누는 특징이 있으므로 이렇게 부름
  - 모든 훈련 세트가 평가에 1번씩 사용되므로 검증 점수가 안정적
  - 기존의 훈련 방법보다 더 많은 데이터로 훈련할 수 있음

<br>

#### k-폴드 교차 검증 구현
1. 훈련 세트 사용하기
   - k-폴드 교차 검증은 훈련, 검증, 테스트 세트를 완전히 나누는 것이 아니라 **검증 세트가 훈련 세트에 포함됨**
     - 전체 데이터 세트를 훈련 세트와 테스트 세트로 1번만 나눈 `x_train_all`과 `y_train_all`을 훈련과 검증에 사용
   ```
   validation_scores = []       # 각 폴드의 검증 점수 저장
   ```
2. k-폴드 교차 검증 구현하기
   ```
   k = 10
   bins = len(x_train_all) // k         # 한 폴드에 들어갈 샘플의 개수, 전체 훈련 세트의 샘플 개수를 k로 나눈 것
   
   for i in range(k):
       start = i*bins           # 검증 폴드 샘플의 시작 인덱스
       end = (i+1)*bins         # 검증 폴드 샘플의 끝 인덱스
       val_fold = x_train_all[start:end]
       val_target = y_train_all[start:end]
    
       train_index = list(range(0, start))+list(range(end, len(x_train_all)))   # 훈련 폴드의 인덱스를 모아둠
       train_fold = x_train_all[train_index]
       train_target = y_train_all[train_index]
    
       train_mean = np.mean(train_fold, axis=0)
       train_std = np.std(train_fold, axis=0)
       train_fold_scaled = (train_fold - train_mean) / train_std
       val_fold_scaled = (val_fold - train_mean) / train_std
    
       lyr = SingleLayer(l2=0.01)
       lyr.fit(train_fold_scaled, train_target, epochs=50)
       score = lyr.score(val_fold_scaled, val_target)
       validation_scores.append(score)
       
   print(np.mean(validation_scores))        # 성능 점수들의 평균

   # 출력
   # 0.9711111111111113
   ```
   - **훈련 데이터의 표준화 전처리를 폴드를 나눈 후에 수행**
     - 검증 폴드의 **정보를 누설하지 않기 위해** 먼저 하지 않음
   - `validation_scores` : 반복문을 진행하며 10개의 검증 폴드로 측정한 성능 점수 저장
   - 이 점수는 1번만 훈련/검증 세트로 나눈 이전의 방법보다 안정적이므로 조금 더 신뢰 가능

<br>

#### 사이킷런으로 교차 검증
- 사이킷런의 `model_selection` 모델에 교차 검증을 위한 `cross_validate()` 함수 존재
1. `cross_validate()` 함수로 교차 검증 점수 계산하기
   ```
   from sklearn.model_selection import cross_validate
   sgd = SGDClassifier(loss='log', penalty='l2', alpha=0.001, random_state=42)
   scores = cross_validate(sgd, x_train_all, y_train_all, cv=10)
   print(np.mean(scores['test_score']))

   # 출력
   # 0.850096618357488
   ```
   - `cross_validate()` : 매개변수 값으로 교차 검증 하고 싶은 모델의 객체, 훈련 데이터, 타깃 데이터 전달하고, cv 매개변수에 교차 검증을 수행할 폴드 수 지정
     - 파이썬 딕셔너리 반환
     - 검증 점수는 `scores['test_score']`에 저장
   - 표준화 전처리를 수행하지 않아 평균 점수가 약 85%로 낮음

<br>

#### 전처리 단계 포함해 교차 검증 수행
- 훈련 세트 전체를 전처리한 후에 `cross_validate()` 함수에 매개변수 값으로 전달하면, 검증 폴드가 표준화 전처리 단계에서 누설됨
- **`Pipeline` 클래스 사용해 교차 검증 수행하기**
  - 검증 폴드가 전처리 단계에서 누설되지 않도록 **전처리 단계와 모델 클래스를 하나로 연결해주는 클래스**
  - 작동 원리
    - 표준화 전처리 단계(평균, 표준 편차 계산)와 `SGDClassifier` 클래스 객체를 `Pipeline` 클래스로 감싸 `cross_validate()` 함수에 전달
    - `cross_validate()` 함수는 훈련 세트를 훈련 폴드와 검증 폴드로 나누기만 하고
    - 전처리 단계와 `SGDClassifier` 클래스 객체의 호출은 `Pipeline` 클래스 객체에서 이루어짐
- 사이킷런에서 `Pipeline` 클래스 객체를 만들어주는 `make_pipeline()` 함수 제공
```
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler    # 사이킷런에서 표준화 전처리를 수행하는 클래스
pipe = make_pipeline(StandardScaler(), sgd)         # 전처리 단계와 모델 객체 전달
scores = cross_validate(pipe, x_train_all, y_train_all, cv=10, return_train_score=True)
print(np.mean(scores['test_score']))

# 출력
# 0.9694202898550724
```
- 평균 검증 점수 높아짐!